{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://legalaffairs.gov.taipei/Content_List.aspx?n=7CBA5467296F9979'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "df_result= pd.DataFrame(columns=['Time', 'Url', 'Question', 'Answer', '點閱數', '資料更新', '資料檢視', '資料維護'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = []\n",
    "x = 0\n",
    "\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    categories = soup.find_all('div', class_='list-text content-list')\n",
    "\n",
    "    for category in categories:\n",
    "        category_text = category.find('a', title=True)\n",
    "        if category_text:\n",
    "            category = category_text['title']\n",
    "            category_list.append(category)\n",
    "else:\n",
    "    print(\"Failed to fetch the webpage. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_url_list = []\n",
    "x = 0\n",
    "\n",
    "for x in categories:\n",
    "    url = 'https://legalaffairs.gov.taipei/' + x.find('a')['href'] + '&page=1&PageSize=100'\n",
    "    category_url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = []\n",
    "url_list = []\n",
    "\n",
    "for url in category_url_list:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    questions = soup.find_all('td', class_='CCMS_jGridView_td_Class_1')\n",
    "    \n",
    "    for question in questions:\n",
    "        question_text = question.find('a').text\n",
    "        question_list.append(question_text)\n",
    "    for x in questions:\n",
    "        url = 'https://legalaffairs.gov.taipei/' + x.find('a')['href']\n",
    "        url_list.append(url)\n",
    "\n",
    "df_result['Question'] = question_list\n",
    "df_result['Url'] = url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "answer_list = []\n",
    "current_time_list = []\n",
    "click_list = []\n",
    "data_update_list = []\n",
    "data_review_list = []\n",
    "data_maintainence_list = []\n",
    "\n",
    "for url in url_list:\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    answers = soup.find_all('div', class_='p')\n",
    "    current_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    clicks = soup.find('span', {'id': 'hitcount'})\n",
    "    click_value = clicks.text.strip() if clicks else None\n",
    "    click_numeric = int(re.search(r'\\d+', click_value).group()) if click_value else None\n",
    "\n",
    "    data_update = soup.find_all('li', {'data-index': '2'})\n",
    "    for li in data_update:\n",
    "        data_update_value = li.find('span')\n",
    "        if data_update_value and '資料更新' in data_update_value.text:\n",
    "            update_info = data_update_value.text.strip().replace('資料更新：', '')\n",
    "            break\n",
    "\n",
    "    data_review = soup.find_all('li', {'data-index': '3'})\n",
    "    for li in data_review:\n",
    "        data_review_value = li.find('span')\n",
    "        if data_review_value and '資料檢視' in data_review_value.text:\n",
    "            review_info = data_review_value.text.strip().replace('資料檢視：', '')\n",
    "            break\n",
    "\n",
    "    data_maintainence = soup.find_all('li', {'data-index': '4'})\n",
    "    for li in data_maintainence:\n",
    "        data_maintainence_value = li.find('span')\n",
    "        if data_maintainence_value and '資料維護' in data_maintainence_value.text:\n",
    "            maintainence_info = data_maintainence_value.text.strip().replace('資料維護：', '')\n",
    "            break\n",
    "\n",
    "    for tag in answers:\n",
    "        answers = tag.text\n",
    "    \n",
    "    answer_list.append(answers)\n",
    "    current_time_list.append(current_time)\n",
    "    click_list.append(click_numeric)\n",
    "    data_update_list.append(update_info)\n",
    "    data_review_list.append(review_info)\n",
    "    data_maintainence_list.append(maintainence_info)\n",
    "\n",
    "df_result['Time'] = current_time_list\n",
    "df_result['Answer'] = answer_list\n",
    "df_result['點閱數'] = click_list\n",
    "df_result['資料更新'] = data_update_list\n",
    "df_result['資料檢視'] = data_review_list\n",
    "df_result['資料維護'] = data_maintainence_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('法務局QA.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
